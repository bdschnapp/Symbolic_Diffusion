{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 142417 records from diffusion_data/trainv7.json\n",
      "Loaded 30518 records from diffusion_data/testv7.json\n",
      "First train record: {'RPN': 'C C x1 * C + sin * C +', 'token_ids': [1, 4, 4, 5, 12, 4, 10, 6, 12, 4, 10, 2], 'X_Y_combined': [[0.6878132224082947, 0.19884493947029114], [-0.6534024477005005, 0.8689918518066406], [-0.06116962805390358, 0.6700705289840698], [0.8045461773872375, 0.20515315234661102], [-0.3449956774711609, 0.8461012244224548], [-0.576971709728241, 0.8821050524711609], [0.01739574410021305, 0.6054874658584595], [-0.39803043007850647, 0.8641659617424011], [-1.6261193752288818, 0.2262020707130432], [0.2445431351661682, 0.4139200448989868], [-1.5616025924682617, 0.25231316685676575], [0.45059362053871155, 0.273221880197525], [-0.019797496497631073, 0.636527419090271], [-0.94711834192276, 0.7169336676597595], [1.5018274784088135, 0.6691287755966187], [0.5895048379898071, 0.21605369448661804], [-0.8914216160774231, 0.7561431527137756], [-0.3446028530597687, 0.8459469676017761], [1.2672282457351685, 0.47136256098747253], [-1.3428105115890503, 0.39118626713752747], [-0.2005811184644699, 0.7709500789642334], [1.4026293754577637, 0.5870029926300049], [0.44159120321273804, 0.2781282365322113], [1.4796584844589233, 0.6512846946716309], [-0.22152335941791534, 0.7839694023132324], [1.3824059963226318, 0.5697438716888428], [-0.4845711588859558, 0.8813340067863464], [1.1163647174835205, 0.35238733887672424], [0.8928183913230896, 0.22892415523529053], [0.3735252916812897, 0.31935060024261475]], 'length': 12}\n",
      "First test record: {'RPN': 'C C x1 * exp * C +', 'token_ids': [1, 4, 4, 5, 12, 8, 12, 4, 10, 2, 0, 0], 'X_Y_combined': [[1.0141469240188599, -0.012527191080152988], [-0.0010719912825152278, 0.20813442766666412], [1.1197470426559448, -0.02944207936525345], [-0.23766513168811798, 0.2787260413169861], [0.4938369393348694, 0.08595604449510574], [1.4307337999343872, -0.07414937019348145], [0.4129640460014343, 0.1038203239440918], [1.2197198867797852, -0.04461587220430374], [1.006415843963623, -0.011251681484282017], [1.2526803016662598, -0.04944685846567154], [-0.6272043585777283, 0.4158173203468323], [-1.1915892362594604, 0.6713139414787292], [-0.8339452147483826, 0.5007705092430115], [-1.0103074312210083, 0.5808802247047424], [-0.4753209054470062, 0.3590148389339447], [0.39651432633399963, 0.10754752159118652], [-0.9352525472640991, 0.5458810925483704], [-1.5425050258636475, 0.8727664947509766], [-0.7058085799217224, 0.44703784584999084], [0.06638509780168533, 0.18955926597118378], [-0.363395094871521, 0.3199557363986969], [0.8980699777603149, 0.007178031373769045], [-0.860903263092041, 0.5125417113304138], [1.250428318977356, -0.04911943897604942], [0.543124258518219, 0.07543424516916275], [-0.1648859679698944, 0.25607216358184814], [-1.1069737672805786, 0.6280331015586853], [1.47415292263031, -0.07983170449733734], [1.348330020904541, -0.06300302594900131], [-0.2702358067035675, 0.28914743661880493]], 'length': 12}\n",
      "Calculating normalization statistics from train_data...\n",
      "Normalization Stats: X ~ N(0.000, 1.000^2), Y ~ N(0.002, 1.000^2)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_diffusion_data(input_dir=\"diffusion_data\", file_name=\"train.json\"):\n",
    "    \"\"\"Load processed diffusion data from the specified JSON file.\"\"\"\n",
    "    file_path = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line.strip())\n",
    "                data.append(record)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding line: {str(e)}\")\n",
    "    \n",
    "    print(f\"Loaded {len(data)} records from {file_path}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = load_diffusion_data(file_name=\"trainv7.json\")\n",
    "test_data = load_diffusion_data(file_name=\"testv7.json\") \n",
    "print(f\"First train record: {train_data[0]}\")\n",
    "print(f\"First test record: {test_data[0]}\")\n",
    "\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "print(\"Calculating normalization statistics from train_data...\")\n",
    "all_coords_list = [item['X_Y_combined'] for item in train_data]\n",
    "if not all_coords_list:\n",
    "    raise ValueError(\"train_data is empty, cannot calculate normalization stats.\")\n",
    "all_coords_np = np.array(all_coords_list, dtype=np.float32) # Shape: (N_samples, N_POINTS, XY_DIM)\n",
    "# Handle potential NaNs or Infs if your data might have them\n",
    "all_coords_np = np.nan_to_num(all_coords_np, nan=0.0, posinf=0.0, neginf=0.0) # Example handling\n",
    "\n",
    "x_mean = np.mean(all_coords_np[:, :, 0])\n",
    "x_std = np.std(all_coords_np[:, :, 0])\n",
    "y_mean = np.mean(all_coords_np[:, :, 1])\n",
    "y_std = np.std(all_coords_np[:, :, 1])\n",
    "\n",
    "# Add small epsilon to std dev to avoid division by zero if data is constant\n",
    "x_std = x_std if x_std > 1e-6 else 1.0\n",
    "y_std = y_std if y_std > 1e-6 else 1.0\n",
    "\n",
    "print(f\"Normalization Stats: X ~ N({x_mean:.3f}, {x_std:.3f}^2), Y ~ N({y_mean:.3f}, {y_std:.3f}^2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve from 0.0552. Patience: 8/8\n",
      "Early stopping triggered after 94 epochs.\n",
      "Training finished.\n",
      "Loading best model weights from best_d3pm_pointnet_crossattn.pth (Val Loss: 0.0552)\n",
      "--- Generating output for test sample index: 0 (using best model) ---\n",
      "Using Normalization Stats for Sampling: X ~ N(0.000, 1.000^2), Y ~ N(0.002, 1.000^2)\n",
      "Ground Truth Tokens:\n",
      "[ 1  4  4  5 12  8 12  4 10  2  0  0]\n",
      "\n",
      "Condition Tensor shape (Normalized): torch.Size([1, 30, 2])\n",
      "\n",
      "Starting generation process...\n",
      "Sampling timestep 1/1000      \n",
      "Sampling complete.\n",
      "\n",
      "Generated Tokens:\n",
      "[ 1  4  4  5 12  8 12  4 10  2 10  2]\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Conditional Discrete Diffusion Probabilistic Model (D3PM) for Symbolic Regression\n",
    "# (PointNet-Style Encoder + Cross-Attention - Syntax Corrected)\n",
    "#\n",
    "# **Features:**\n",
    "# - PointNet-Style Encoder for condition processing.\n",
    "# - Cross-Attention Conditioning.\n",
    "# - Increased Model Capacity.\n",
    "# - Live Plotting & Coordinate Normalization.\n",
    "# - Early stopping & Best model saving.\n",
    "\n",
    "# %%\n",
    "# === Imports ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# --- Configuration (Using User-Provided Values) ---\n",
    "# Data Parameters\n",
    "SEQ_LEN = 12 \n",
    "N_POINTS = 30\n",
    "XY_DIM = 2\n",
    "PAD_TOKEN_ID = 0\n",
    "VOCAB_SIZE = 17\n",
    "\n",
    "# Model Capacity (Large)\n",
    "EMBED_DIM = 192\n",
    "NUM_HEADS = 12\n",
    "NUM_LAYERS = 8\n",
    "DIM_FEEDFORWARD = 768\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Diffusion Parameters\n",
    "NUM_TIMESTEPS = 1000\n",
    "BETA_START = 0.0001\n",
    "BETA_END = 0.02\n",
    "SCHEDULE_TYPE = 'cosine'\n",
    "\n",
    "# Training Parameters\n",
    "BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 2048\n",
    "LEARNING_RATE = 1e-4 # Reset to user's value for this run\n",
    "EPOCHS = 150\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PATIENCE = 8\n",
    "BEST_MODEL_PATH = \"best_d3pm_pointnet_crossattn.pth\" # New path\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(42)\n",
    "\n",
    "def linear_beta_schedule(timesteps, beta_start=BETA_START, beta_end=BETA_END):\n",
    "    \"\"\"Linear schedule from beta_start to beta_end.\"\"\"\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype=torch.float64)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"Cosine schedule.\"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float64)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    \"\"\"Extract coefficients at specified timesteps t, reshaping to x_shape.\"\"\"\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "\n",
    "# --- Diffusion Logic ---\n",
    "class DiscreteDiffusion:\n",
    "    def __init__(self, num_timesteps=NUM_TIMESTEPS, vocab_size=VOCAB_SIZE, device=DEVICE): # Correct ':'\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = device\n",
    "\n",
    "        if SCHEDULE_TYPE == 'linear': # Correct ':'\n",
    "            self.betas = linear_beta_schedule(num_timesteps).to(device)\n",
    "        elif SCHEDULE_TYPE == 'cosine': # Correct ':'\n",
    "            self.betas = cosine_beta_schedule(num_timesteps).to(device)\n",
    "        else: # Correct ':'\n",
    "            raise ValueError(f\"Unknown schedule type: {SCHEDULE_TYPE}\")\n",
    "\n",
    "        self.alphas = (1. - self.betas).to(device)\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0).to(device)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0).to(device)\n",
    "\n",
    "        self.log_q_t_x_t_minus_1 = self._compute_log_q_t_x_t_minus_1()\n",
    "        self.log_q_t_x_0 = self._compute_log_q_t_x_0()\n",
    "        self.log_q_t_minus_1_x_t_x_0 = self._compute_log_q_t_minus_1_x_t_x_0()\n",
    "\n",
    "    def _compute_log_q_t_x_t_minus_1(self): # Correct ':'\n",
    "        \"\"\" Compute log q(x_t | x_{t-1}) \"\"\"\n",
    "        log_q = torch.zeros(self.num_timesteps, self.vocab_size, self.vocab_size, device=self.device, dtype=torch.float64)\n",
    "        eye = torch.eye(self.vocab_size, device=self.device) # Precompute eye\n",
    "        for t in range(self.num_timesteps): # Correct ':'\n",
    "            beta_t = self.betas[t]\n",
    "            diag_indices = torch.arange(self.vocab_size, device=self.device)\n",
    "            log_q[t, diag_indices, diag_indices] = torch.log(1.0 - beta_t + beta_t / self.vocab_size)\n",
    "            off_diag_val = torch.log(beta_t / self.vocab_size)\n",
    "            log_q[t] = log_q[t] + off_diag_val * (1.0 - eye)\n",
    "        return log_q.float()\n",
    "\n",
    "    def _compute_log_q_t_x_0(self): # Correct ':'\n",
    "        \"\"\" Compute log q(x_t | x_0) \"\"\"\n",
    "        log_q = torch.zeros(self.num_timesteps, self.vocab_size, self.vocab_size, device=self.device, dtype=torch.float64)\n",
    "        eye = torch.eye(self.vocab_size, device=self.device) # Precompute eye\n",
    "        # Use a small epsilon for clamping\n",
    "        epsilon = 1e-40 # A very small positive number\n",
    "\n",
    "        for t in range(self.num_timesteps): # Correct ':'\n",
    "            alpha_bar_t = self.alphas_cumprod[t]\n",
    "            diag_indices = torch.arange(self.vocab_size, device=self.device)\n",
    "\n",
    "            # Calculate terms\n",
    "            diag_term = alpha_bar_t + (1.0 - alpha_bar_t) / self.vocab_size\n",
    "            off_diag_term = (1.0 - alpha_bar_t) / self.vocab_size\n",
    "\n",
    "            # --- Clamp arguments before log ---\n",
    "            log_diag_term_clamped = torch.log(diag_term.clamp(min=epsilon))\n",
    "            off_diag_val_clamped = torch.log(off_diag_term.clamp(min=epsilon))\n",
    "            # --- End Clamp ---\n",
    "\n",
    "            # Assign diagonal values\n",
    "            log_q[t, diag_indices, diag_indices] = log_diag_term_clamped\n",
    "\n",
    "            # Assign off-diagonal values using the original method's logic\n",
    "            # Add the clamped log off-diagonal value to non-diagonal elements\n",
    "            log_q[t] = log_q[t] + off_diag_val_clamped * (1.0 - eye)\n",
    "\n",
    "        return log_q.float()\n",
    "\n",
    "    def _compute_log_q_t_minus_1_x_t_x_0(self): # Correct ':'\n",
    "        \"\"\" Compute log q(x_{t-1} | x_t, x_0) \"\"\"\n",
    "        log_q_posterior = torch.zeros(self.num_timesteps, self.vocab_size, self.vocab_size, self.vocab_size, device=self.device, dtype=torch.float64)\n",
    "        log_q_t_x_t_minus_1_64 = self.log_q_t_x_t_minus_1.double()\n",
    "        log_q_t_x_0_64 = self.log_q_t_x_0.double()\n",
    "        for t in range(1, self.num_timesteps): # Correct ':'\n",
    "            log_q_t_given_t_minus_1 = log_q_t_x_t_minus_1_64[t]\n",
    "            log_q_t_minus_1_given_0 = log_q_t_x_0_64[t-1]\n",
    "            log_q_posterior[t] = log_q_t_given_t_minus_1.unsqueeze(1) + log_q_t_minus_1_given_0.unsqueeze(0)\n",
    "        log_denominator = torch.logsumexp(log_q_posterior, dim=-1, keepdim=True)\n",
    "        log_denominator = torch.where(torch.isinf(log_denominator), torch.zeros_like(log_denominator), log_denominator)\n",
    "        log_q_posterior = log_q_posterior - log_denominator\n",
    "        log_q_posterior = torch.clamp(log_q_posterior, -100.0, 0.0)\n",
    "        return log_q_posterior.float()\n",
    "\n",
    "    def q_sample(self, x_start, t): # Correct ':'\n",
    "        \"\"\" Sample x_t given x_0 and t \"\"\"\n",
    "        batch_size, seq_len = x_start.shape\n",
    "        log_q_t_x_0_for_batch_t = self.log_q_t_x_0[t]\n",
    "        x_start_expanded = x_start.unsqueeze(-1)\n",
    "        log_q_t_x_0_expanded = log_q_t_x_0_for_batch_t.unsqueeze(1).expand(-1, seq_len, -1, -1)\n",
    "        x_start_indices = x_start_expanded.unsqueeze(-1).expand(-1, -1, self.vocab_size, -1)\n",
    "        x_start_indices = torch.clamp(x_start_indices, 0, self.vocab_size - 1)\n",
    "        log_probs = torch.gather(log_q_t_x_0_expanded, dim=3, index=x_start_indices).squeeze(-1)\n",
    "        gumbel_noise = torch.rand_like(log_probs)\n",
    "        gumbel_noise = -torch.log(-torch.log(gumbel_noise.clamp(min=1e-9)) + 1e-9)\n",
    "        x_t = torch.argmax(log_probs + gumbel_noise, dim=-1)\n",
    "        return x_t.long()\n",
    "\n",
    "    def q_posterior_log_probs(self, x_0, x_t, t): # Correct ':'\n",
    "        \"\"\" Compute log q(x_{t-1} | x_t, x_0) \"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "        log_q_posterior_t = self.log_q_t_minus_1_x_t_x_0[t]\n",
    "        log_q_posterior_t = log_q_posterior_t.unsqueeze(1).expand(-1, seq_len, -1, -1, -1)\n",
    "        x_t_idx = x_t.view(batch_size, seq_len, 1, 1, 1).expand(-1, -1, -1, self.vocab_size, self.vocab_size)\n",
    "        x_t_idx = torch.clamp(x_t_idx, 0, self.vocab_size - 1)\n",
    "        log_q_posterior_t_i = torch.gather(log_q_posterior_t, dim=2, index=x_t_idx).squeeze(2)\n",
    "        x_0_idx = x_0.view(batch_size, seq_len, 1, 1).expand(-1, -1, -1, self.vocab_size)\n",
    "        x_0_idx = torch.clamp(x_0_idx, 0, self.vocab_size - 1)\n",
    "        log_q_posterior_t_i_j = torch.gather(log_q_posterior_t_i, dim=2, index=x_0_idx).squeeze(2)\n",
    "        return log_q_posterior_t_i_j\n",
    "\n",
    "    def p_log_probs(self, model, x_t, t, condition): # Correct ':'\n",
    "        \"\"\" Compute log p_theta(x_0 | x_t, t, condition) \"\"\"\n",
    "        log_pred_x0 = model(x_t, t, condition)\n",
    "        return F.log_softmax(log_pred_x0, dim=-1)\n",
    "\n",
    "    def p_sample(self, model, x_t, t, condition): # Correct ':'\n",
    "        \"\"\" Sample x_{t-1} from p_theta(x_{t-1} | x_t, t, condition) \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "        log_pred_x0 = self.p_log_probs(model, x_t, t, condition)\n",
    "        log_q_posterior_t = self.log_q_t_minus_1_x_t_x_0[t]\n",
    "        log_q_posterior_t = log_q_posterior_t.unsqueeze(1).expand(-1, seq_len, -1, -1, -1)\n",
    "        x_t_idx = x_t.view(batch_size, seq_len, 1, 1, 1).expand(-1, -1, -1, self.vocab_size, self.vocab_size)\n",
    "        x_t_idx = torch.clamp(x_t_idx, 0, self.vocab_size - 1)\n",
    "        log_q_posterior_t_i = torch.gather(log_q_posterior_t, dim=2, index=x_t_idx).squeeze(2)\n",
    "        log_pred_x0_expanded = log_pred_x0.unsqueeze(-1)\n",
    "        log_sum_terms = log_q_posterior_t_i + log_pred_x0_expanded\n",
    "        log_p_t_minus_1_given_t = torch.logsumexp(log_sum_terms, dim=2)\n",
    "        log_p_t_minus_1_given_t = F.log_softmax(log_p_t_minus_1_given_t, dim=-1)\n",
    "        gumbel_noise = torch.rand_like(log_p_t_minus_1_given_t)\n",
    "        gumbel_noise = -torch.log(-torch.log(gumbel_noise.clamp(min=1e-9)) + 1e-9)\n",
    "        x_t_minus_1 = torch.argmax(log_p_t_minus_1_given_t + gumbel_noise, dim=-1)\n",
    "        return x_t_minus_1.long()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, condition, shape): # Correct ':'\n",
    "        \"\"\" Generate samples from the model \"\"\"\n",
    "        batch_size, seq_len = shape\n",
    "        device = self.device\n",
    "        model.eval() # Ensure model is in eval mode for sampling\n",
    "        x_t = torch.randint(1, self.vocab_size, size=shape, device=device).long() # Avoid sampling PAD initially if possible\n",
    "\n",
    "        for t in reversed(range(0, self.num_timesteps)): # Correct ':'\n",
    "            print(f\"\\rSampling timestep {t+1}/{self.num_timesteps}   \", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            if t > 0: # Correct ':'\n",
    "                 x_t = self.p_sample(model, x_t, t_tensor, condition)\n",
    "            else: # Correct ':'\n",
    "                 # At t=0, use the model's prediction of x_0 directly\n",
    "                 log_pred_x0 = self.p_log_probs(model, x_t, t_tensor, condition)\n",
    "                 # Sample x_0 from the final prediction\n",
    "                 gumbel_noise = torch.rand_like(log_pred_x0)\n",
    "                 gumbel_noise = -torch.log(-torch.log(gumbel_noise.clamp(min=1e-9)) + 1e-9)\n",
    "                 x_t = torch.argmax(log_pred_x0 + gumbel_noise, dim=-1).long()\n",
    "\n",
    "        print(\"\\nSampling complete.\")\n",
    "        model.train() # Set back to train mode after sampling\n",
    "        return x_t\n",
    "\n",
    "    def compute_loss(self, model, x_start, condition, pad_token_id=PAD_TOKEN_ID): # Correct ':'\n",
    "        \"\"\" Compute the training loss \"\"\"\n",
    "        batch_size, seq_len = x_start.shape\n",
    "        device = x_start.device\n",
    "        t = torch.randint(0, self.num_timesteps, (batch_size,), device=device).long()\n",
    "        x_t = self.q_sample(x_start, t)\n",
    "        log_pred_x0 = self.p_log_probs(model, x_t, t, condition)\n",
    "        # Calculate NLL loss\n",
    "        loss = F.nll_loss(log_pred_x0.permute(0, 2, 1), # Needs [B, K, S] for nll_loss\n",
    "                          x_start,\n",
    "                          ignore_index=pad_token_id,\n",
    "                          reduction='none') # [B, S]\n",
    "        # Average loss over non-padding tokens\n",
    "        mask = (x_start != pad_token_id).float()\n",
    "        loss = (loss * mask).sum() / mask.sum().clamp(min=1) # Average over non-pad tokens per batch\n",
    "        return loss\n",
    "\n",
    "\n",
    "# --- Model Architecture Components ---\n",
    "class PositionalEncoding(nn.Module): # Correct ':'\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000): # Correct ':'\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1) # Shape: [max_len, 1, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x): # Correct ':'\n",
    "        # Input x expected shape: [seq_len, batch_size, embedding_dim]\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TimestepEmbedding(nn.Module): # Correct ':'\n",
    "    def __init__(self, dim, max_period=10000): # Correct ':'\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_period = max_period\n",
    "\n",
    "    def forward(self, t): # Correct ':'\n",
    "        device = t.device\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-math.log(self.max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
    "        args = t[:, None].float() * freqs[None, :]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if self.dim % 2: # Correct ':' # Handle odd embedding dim\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "# --- PointNet-Style Encoder for Conditioning ---\n",
    "class PointCloudEncoder(nn.Module): # Correct ':'\n",
    "    def __init__(self, input_dim=XY_DIM, embed_dim=EMBED_DIM): # Correct ':'\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Shared MLPs implemented using Conv1d\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Final MLP after max pooling\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(256, embed_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim * 2, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, point_cloud): # Correct ':'\n",
    "        # point_cloud shape: (B, N_POINTS, XY_DIM)\n",
    "        x = point_cloud.permute(0, 2, 1) # (B, XY_DIM, N_POINTS)\n",
    "        point_features = self.mlp1(x) # (B, 256, N_POINTS)\n",
    "        global_feature, _ = torch.max(point_features, dim=2) # (B, 256)\n",
    "        condition_embedding = self.mlp2(global_feature) # (B, embed_dim)\n",
    "        return condition_embedding\n",
    "\n",
    "# --- Modified ConditionalD3PMTransformer ---\n",
    "class ConditionalD3PMTransformer(nn.Module): # Correct ':'\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, dim_feedforward,\n",
    "                 seq_len, condition_dim, # condition_dim is XY_DIM for PointCloudEncoder input\n",
    "                 num_timesteps, dropout=0.1): # Correct ':'\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=PAD_TOKEN_ID)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim, dropout, max_len=seq_len + 1)\n",
    "        self.timestep_embedding = nn.Sequential(\n",
    "            TimestepEmbedding(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim), nn.SiLU(), nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        # Use PointCloudEncoder for condition\n",
    "        self.condition_encoder = PointCloudEncoder(input_dim=XY_DIM, embed_dim=embed_dim)\n",
    "\n",
    "        # Optional: Condition Dropout Probability\n",
    "        self.condition_dropout_prob = 0.1 # Set to 0 to disable\n",
    "\n",
    "        # Manual Transformer Block Components\n",
    "        self.encoder_self_attn_layers = nn.ModuleList()\n",
    "        self.encoder_cross_attn_layers = nn.ModuleList()\n",
    "        self.encoder_ffn_layers = nn.ModuleList()\n",
    "        self.encoder_norm1_layers = nn.ModuleList()\n",
    "        self.encoder_norm2_layers = nn.ModuleList()\n",
    "        self.encoder_norm3_layers = nn.ModuleList()\n",
    "        self.dropout_layers = nn.ModuleList()\n",
    "\n",
    "        for _ in range(num_layers): # Correct ':'\n",
    "            self.encoder_self_attn_layers.append(nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True))\n",
    "            self.encoder_cross_attn_layers.append(nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True))\n",
    "            self.encoder_ffn_layers.append(nn.Sequential(\n",
    "                nn.Linear(embed_dim, dim_feedforward), nn.GELU(), nn.Dropout(dropout),\n",
    "                nn.Linear(dim_feedforward, embed_dim)\n",
    "            ))\n",
    "            self.encoder_norm1_layers.append(nn.LayerNorm(embed_dim))\n",
    "            self.encoder_norm2_layers.append(nn.LayerNorm(embed_dim))\n",
    "            self.encoder_norm3_layers.append(nn.LayerNorm(embed_dim))\n",
    "            self.dropout_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self): # Correct ':'\n",
    "        initrange = 0.1\n",
    "        self.token_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        if self.token_embedding.padding_idx is not None: # Correct ':'\n",
    "             self.token_embedding.weight.data[self.token_embedding.padding_idx].zero_()\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        # Init PointCloudEncoder layers\n",
    "        for layer in self.condition_encoder.modules(): # Correct ':'\n",
    "             if isinstance(layer, (nn.Conv1d, nn.Linear)): # Correct ':'\n",
    "                 layer.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                 if layer.bias is not None: # Correct ':'\n",
    "                     layer.bias.data.zero_()\n",
    "             elif isinstance(layer, nn.BatchNorm1d): # Correct ':'\n",
    "                 layer.weight.data.fill_(1.0)\n",
    "                 layer.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, t, condition): # Correct ':'\n",
    "        # CONDITION INPUT SHAPE CHANGE: Expects (B, N_POINTS, XY_DIM)\n",
    "        batch_size, seq_len = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # 1. Embeddings\n",
    "        token_emb = self.token_embedding(x) * math.sqrt(self.embed_dim)\n",
    "        token_emb_permuted = token_emb.transpose(0, 1)\n",
    "        pos_emb_permuted = self.positional_encoding(token_emb_permuted)\n",
    "        pos_emb = pos_emb_permuted.transpose(0, 1)\n",
    "        time_emb = self.timestep_embedding(t)\n",
    "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
    "\n",
    "        # 2. Condition Embedding\n",
    "        cond_emb_proj = self.condition_encoder(condition)\n",
    "\n",
    "        # Optional: Condition Dropout\n",
    "        if self.training and self.condition_dropout_prob > 0: # Correct ':'\n",
    "            mask = (torch.rand(cond_emb_proj.shape[0], 1, device=cond_emb_proj.device) > self.condition_dropout_prob).float()\n",
    "            cond_emb_proj = cond_emb_proj * mask\n",
    "\n",
    "        cond_kv = cond_emb_proj.unsqueeze(1)\n",
    "\n",
    "        # 3. Initial sequence representation\n",
    "        current_input = pos_emb + time_emb\n",
    "\n",
    "        # 4. Padding mask\n",
    "        padding_mask = (x == PAD_TOKEN_ID)\n",
    "\n",
    "        # --- Transformer Blocks Loop ---\n",
    "        for i in range(self.num_layers): # Correct ':'\n",
    "            # Self-Attention\n",
    "            sa_norm_input = self.encoder_norm1_layers[i](current_input)\n",
    "            sa_output, _ = self.encoder_self_attn_layers[i](query=sa_norm_input, key=sa_norm_input, value=sa_norm_input, key_padding_mask=padding_mask)\n",
    "            x = current_input + self.dropout_layers[i](sa_output)\n",
    "            # Cross-Attention\n",
    "            ca_norm_input = self.encoder_norm3_layers[i](x)\n",
    "            ca_output, _ = self.encoder_cross_attn_layers[i](query=ca_norm_input, key=cond_kv, value=cond_kv)\n",
    "            x = x + self.dropout_layers[i](ca_output)\n",
    "            # Feed-Forward\n",
    "            ffn_norm_input = self.encoder_norm2_layers[i](x)\n",
    "            ffn_output = self.encoder_ffn_layers[i](ffn_norm_input)\n",
    "            x = x + ffn_output\n",
    "            current_input = x\n",
    "        # --- End Loop ---\n",
    "\n",
    "        transformer_output = current_input\n",
    "        output_logits = self.output_layer(transformer_output)\n",
    "        return output_logits\n",
    "\n",
    "\n",
    "# --- Dataset (MODIFIED) ---\n",
    "class SymbolicRegressionDataset(Dataset): # Correct ':'\n",
    "    def __init__(self, data, x_mean=0.0, x_std=1.0, y_mean=0.0, y_std=1.0): # Correct ':'\n",
    "        self.data = data\n",
    "        self.x_mean, self.x_std = x_mean, x_std\n",
    "        self.y_mean, self.y_std = y_mean, y_std\n",
    "        self.processed_data = []\n",
    "        for item in data: # Correct ':'\n",
    "             token_ids = np.array(item['token_ids'], dtype=np.int64)\n",
    "             if np.any(token_ids >= VOCAB_SIZE): # Correct ':'\n",
    "                 token_ids = np.clip(token_ids, 0, VOCAB_SIZE - 1)\n",
    "\n",
    "             xy_coords = np.array(item['X_Y_combined'], dtype=np.float32)\n",
    "             # Apply Normalization\n",
    "             xy_coords[:, 0] = (xy_coords[:, 0] - self.x_mean) / (self.x_std + 1e-8)\n",
    "             xy_coords[:, 1] = (xy_coords[:, 1] - self.y_mean) / (self.y_std + 1e-8)\n",
    "\n",
    "             # Store unflattened tensor\n",
    "             condition_tensor = torch.from_numpy(xy_coords)\n",
    "\n",
    "             self.processed_data.append({\n",
    "                 'token_ids': torch.from_numpy(token_ids),\n",
    "                 'condition': condition_tensor\n",
    "             })\n",
    "\n",
    "    def __len__(self): # Correct ':'\n",
    "        return len(self.processed_data)\n",
    "\n",
    "    def __getitem__(self, idx): # Correct ':'\n",
    "        return self.processed_data[idx]\n",
    "\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "@torch.no_grad()\n",
    "def evaluate(model, diffusion, val_loader, device): # Correct ':'\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for batch in val_loader: # Correct ':'\n",
    "        x_start = batch['token_ids'].to(device)\n",
    "        condition = batch['condition'].to(device) # Shape (B, N_POINTS, XY_DIM)\n",
    "        if x_start.max() >= VOCAB_SIZE or x_start.min() < 0: # Correct ':'\n",
    "             print(f\"\\nWarning: Invalid token ID in validation batch. Skipping.\")\n",
    "             continue\n",
    "        loss = diffusion.compute_loss(model, x_start, condition, pad_token_id=PAD_TOKEN_ID)\n",
    "        if not torch.isnan(loss): # Correct ':'\n",
    "             total_val_loss += loss.item()\n",
    "             num_batches += 1\n",
    "        else: # Correct ':'\n",
    "            print(\"\\nWarning: NaN loss encountered during validation. Skipping batch.\")\n",
    "\n",
    "    model.train()\n",
    "    if num_batches == 0: # Correct ':'\n",
    "        print(\"\\nWarning: No valid batches processed during evaluation.\")\n",
    "        return float('inf')\n",
    "    return total_val_loss / num_batches\n",
    "\n",
    "\n",
    "# --- Training Function ---\n",
    "def train(train_data, test_data): # Correct ':'\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"Training data size: {len(train_data)}\")\n",
    "    print(f\"Validation (test) data size: {len(test_data)}\")\n",
    "\n",
    "    if not train_data: # Correct ':'\n",
    "        raise ValueError(\"train_data list is empty.\")\n",
    "    perform_validation = bool(test_data)\n",
    "    if not perform_validation: # Correct ':'\n",
    "        print(\"Warning: test_data is empty. Skipping validation.\")\n",
    "\n",
    "    # Calculate Normalization Stats\n",
    "    print(\"Calculating normalization statistics from train_data...\")\n",
    "    all_coords_list = [item['X_Y_combined'] for item in train_data]\n",
    "    if not all_coords_list: # Correct ':'\n",
    "        raise ValueError(\"train_data is empty, cannot calculate normalization stats.\")\n",
    "    all_coords_np = np.array(all_coords_list, dtype=np.float32)\n",
    "    all_coords_np = np.nan_to_num(all_coords_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    x_mean = np.mean(all_coords_np[:, :, 0]); x_std = np.std(all_coords_np[:, :, 0])\n",
    "    y_mean = np.mean(all_coords_np[:, :, 1]); y_std = np.std(all_coords_np[:, :, 1])\n",
    "    x_std = x_std if x_std > 1e-6 else 1.0; y_std = y_std if y_std > 1e-6 else 1.0\n",
    "    print(f\"Normalization Stats: X ~ N({x_mean:.3f}, {x_std:.3f}^2), Y ~ N({y_mean:.3f}, {y_std:.3f}^2)\")\n",
    "\n",
    "    # Create Datasets\n",
    "    train_dataset = SymbolicRegressionDataset(train_data, x_mean, x_std, y_mean, y_std)\n",
    "    val_loader = None\n",
    "    if perform_validation: # Correct ':'\n",
    "        val_dataset = SymbolicRegressionDataset(test_data, x_mean, x_std, y_mean, y_std)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=VALIDATION_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True if DEVICE == \"cuda\" else False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True if DEVICE == \"cuda\" else False)\n",
    "\n",
    "    # Initialize Model\n",
    "    model = ConditionalD3PMTransformer(\n",
    "        vocab_size=VOCAB_SIZE, embed_dim=EMBED_DIM, num_heads=NUM_HEADS, num_layers=NUM_LAYERS,\n",
    "        dim_feedforward=DIM_FEEDFORWARD, seq_len=SEQ_LEN,\n",
    "        condition_dim=XY_DIM, # Pass XY_DIM\n",
    "        num_timesteps=NUM_TIMESTEPS, dropout=DROPOUT\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    diffusion = DiscreteDiffusion(num_timesteps=NUM_TIMESTEPS, vocab_size=VOCAB_SIZE, device=DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=max(1, PATIENCE // 2), verbose=True)\n",
    "\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    if perform_validation: # Correct ':'\n",
    "        print(f\"Early stopping patience: {PATIENCE}\")\n",
    "        print(f\"Best model will be saved to: {BEST_MODEL_PATH}\")\n",
    "\n",
    "    best_val_loss = float('inf'); epochs_no_improve = 0\n",
    "    epochs_plotted = []; train_losses = []; val_losses = []\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    for epoch in range(EPOCHS): # Correct ':'\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        processed_batches = 0\n",
    "\n",
    "        for i, batch in enumerate(train_loader): # Correct ':'\n",
    "            optimizer.zero_grad()\n",
    "            x_start = batch['token_ids'].to(DEVICE)\n",
    "            condition = batch['condition'].to(DEVICE) # Shape (B, N_POINTS, XY_DIM)\n",
    "\n",
    "            if x_start.max() >= VOCAB_SIZE or x_start.min() < 0: # Correct ':'\n",
    "                 print(f\"\\nWarning: Invalid token ID in train batch. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            loss = diffusion.compute_loss(model, x_start, condition, pad_token_id=PAD_TOKEN_ID)\n",
    "\n",
    "            if torch.isnan(loss): # Correct ':'\n",
    "                print(f\"\\nWarning: NaN loss detected during training. Skipping batch.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            processed_batches += 1\n",
    "\n",
    "            print(f\"\\rEpoch [{epoch+1}/{EPOCHS}], Step [{i+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}   \", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # --- End of Epoch ---\n",
    "        avg_train_loss = total_train_loss / processed_batches if processed_batches > 0 else 0\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # Validation Step\n",
    "        avg_val_loss = float('inf')\n",
    "        if perform_validation and val_loader: # Correct ':'\n",
    "            print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] completed in {epoch_time:.2f}s. Avg Train Loss: {avg_train_loss:.4f}. Evaluating...\", end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            avg_val_loss = evaluate(model, diffusion, val_loader, DEVICE)\n",
    "            print(f\" Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "            scheduler.step(avg_val_loss)\n",
    "        else: # Correct ':'\n",
    "             print(f\"\\nEpoch [{epoch+1}/{EPOCHS}] completed in {epoch_time:.2f}s. Avg Train Loss: {avg_train_loss:.4f}. (Validation Skipped)\")\n",
    "\n",
    "        # Store losses for plotting\n",
    "        epochs_plotted.append(epoch + 1)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        if perform_validation: # Correct ':'\n",
    "             val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Live Plotting\n",
    "        try: # Correct ':'\n",
    "            display.clear_output(wait=True)\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.plot(epochs_plotted, train_losses, 'bo-', label='Training Loss')\n",
    "            if val_losses: # Correct ':'\n",
    "                ax.plot(epochs_plotted, val_losses, 'ro-', label='Validation Loss')\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel('Loss')\n",
    "            ax.set_title('Training and Validation Loss Over Epochs')\n",
    "            ax.grid(True)\n",
    "            ax.legend()\n",
    "            if max(train_losses, default=0) > 5 * min(train_losses, default=1): # Correct ':'\n",
    "                 ax.set_yscale('log')\n",
    "            display.display(fig)\n",
    "            plt.close(fig)\n",
    "        except Exception as e: # Correct ':'\n",
    "            print(f\"\\nError during plotting: {e}\")\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if perform_validation: # Correct ':'\n",
    "            if avg_val_loss < best_val_loss: # Correct ':'\n",
    "                print(f\"Validation loss improved ({best_val_loss:.4f} --> {avg_val_loss:.4f}). Saving model...\")\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "                epochs_no_improve = 0\n",
    "            else: # Correct ':'\n",
    "                epochs_no_improve += 1\n",
    "                print(f\"Validation loss did not improve from {best_val_loss:.4f}. Patience: {epochs_no_improve}/{PATIENCE}\")\n",
    "                if epochs_no_improve >= PATIENCE: # Correct ':'\n",
    "                    print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # End of Training Loop\n",
    "    print(\"Training finished.\")\n",
    "    if perform_validation and os.path.exists(BEST_MODEL_PATH): # Correct ':'\n",
    "        print(f\"Loading best model weights from {BEST_MODEL_PATH} (Val Loss: {best_val_loss:.4f})\")\n",
    "        model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
    "    elif perform_validation: # Correct ':'\n",
    "        print(\"Warning: Best model path not found, but validation was performed. Returning model from last epoch.\")\n",
    "    else: # Correct ':'\n",
    "        print(\"Validation was not performed. Returning model from last epoch.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Run Training**\n",
    "# Make sure `train_data` and `test_data` are loaded in your notebook environment before executing the cell below.\n",
    "\n",
    "# %%\n",
    "# === EXECUTION ===\n",
    "if 'train_data' not in locals(): # Correct ':'\n",
    "     print(\"ERROR: 'train_data' is not defined.\")\n",
    "     print(\"Creating minimal dummy data for structure testing ONLY.\")\n",
    "     train_data = []\n",
    "     def generate_dummy_item(seq_len=SEQ_LEN, n_points=N_POINTS, vocab_size=VOCAB_SIZE): # Correct ':'\n",
    "         tokens = np.random.randint(1, vocab_size, size=seq_len); pad_len = random.randint(0, seq_len//2);\n",
    "         if pad_len > 0: # Correct ':'\n",
    "             tokens[-pad_len:] = PAD_TOKEN_ID\n",
    "         tokens = np.clip(tokens, 0, vocab_size - 1); xy = np.random.rand(n_points, XY_DIM) * 10 - 5\n",
    "         xy = xy.reshape(n_points, XY_DIM) # Ensure shape\n",
    "         return {'token_ids': tokens, 'X_Y_combined': xy}\n",
    "     train_data = [generate_dummy_item() for _ in range(BATCH_SIZE * 4)]\n",
    "     test_data = [generate_dummy_item() for _ in range(VALIDATION_BATCH_SIZE * 2)]\n",
    "     # test_data = [] # To disable validation\n",
    "\n",
    "trained_model = train(train_data, test_data)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Generate and Compare Sample Output (Using Best Model)\n",
    "# This cell loads a sample from the `test_data`, prints its ground truth token sequence, and uses the **best performing model** (`trained_model` loaded with best weights) to generate a predicted token sequence.\n",
    "\n",
    "# %%\n",
    "# === SAMPLING ===\n",
    "import torch\n",
    "import numpy as np\n",
    "sample_idx = 0 # Use index 0 for sampling example\n",
    "\n",
    "if 'train_data' not in locals() or not train_data: # Correct ':'\n",
    "    print(\"ERROR: 'train_data' is not defined. Cannot calculate normalization stats for sampling.\")\n",
    "elif 'test_data' not in locals(): # Correct ':'\n",
    "    print(\"ERROR: 'test_data' is not defined. Cannot perform sampling.\")\n",
    "elif not test_data: # Correct ':'\n",
    "    print(\"Warning: 'test_data' is empty. Cannot perform sampling.\")\n",
    "elif sample_idx >= len(test_data): # Correct ':'\n",
    "    print(f\"ERROR: sample_idx ({sample_idx}) is out of bounds for test_data (size {len(test_data)}).\")\n",
    "else: # Correct ':'\n",
    "    print(f\"--- Generating output for test sample index: {sample_idx} (using best model) ---\")\n",
    "    try: # Correct ':'\n",
    "        # Recalculate normalization stats from train_data\n",
    "        all_coords_list_samp = [item['X_Y_combined'] for item in train_data]\n",
    "        all_coords_np_samp = np.array(all_coords_list_samp, dtype=np.float32)\n",
    "        all_coords_np_samp = np.nan_to_num(all_coords_np_samp, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        x_mean_samp = np.mean(all_coords_np_samp[:, :, 0]); x_std_samp = np.std(all_coords_np_samp[:, :, 0])\n",
    "        y_mean_samp = np.mean(all_coords_np_samp[:, :, 1]); y_std_samp = np.std(all_coords_np_samp[:, :, 1])\n",
    "        x_std_samp = x_std_samp if x_std_samp > 1e-6 else 1.0; y_std_samp = y_std_samp if y_std_samp > 1e-6 else 1.0\n",
    "        print(f\"Using Normalization Stats for Sampling: X ~ N({x_mean_samp:.3f}, {x_std_samp:.3f}^2), Y ~ N({y_mean_samp:.3f}, {y_std_samp:.3f}^2)\")\n",
    "\n",
    "        # Get UNFLATTENED data item\n",
    "        data_item_to_generate = test_data[sample_idx]\n",
    "        true_tokens = np.array(data_item_to_generate['token_ids'])\n",
    "        xy_coords_orig = np.array(data_item_to_generate['X_Y_combined'], dtype=np.float32)\n",
    "\n",
    "        # Normalize and Prepare Condition Tensor\n",
    "        xy_coords_norm = np.copy(xy_coords_orig)\n",
    "        xy_coords_norm[:, 0] = (xy_coords_norm[:, 0] - x_mean_samp) / (x_std_samp + 1e-8)\n",
    "        xy_coords_norm[:, 1] = (xy_coords_norm[:, 1] - y_mean_samp) / (y_std_samp + 1e-8)\n",
    "        condition_tensor = torch.from_numpy(xy_coords_norm).float()\n",
    "        condition_tensor = condition_tensor.unsqueeze(0).to(DEVICE) # (1, N_POINTS, XY_DIM)\n",
    "\n",
    "        print(f\"Ground Truth Tokens:\\n{true_tokens}\");\n",
    "        print(f\"\\nCondition Tensor shape (Normalized): {condition_tensor.shape}\")\n",
    "\n",
    "        diffusion_sampler = DiscreteDiffusion(num_timesteps=NUM_TIMESTEPS, vocab_size=VOCAB_SIZE, device=DEVICE)\n",
    "\n",
    "        if 'trained_model' not in locals() or trained_model is None: # Correct ':'\n",
    "             print(\"ERROR: 'trained_model' not found or not loaded.\")\n",
    "        else: # Correct ':'\n",
    "            trained_model.to(DEVICE); trained_model.eval()\n",
    "            print(\"\\nStarting generation process...\")\n",
    "            with torch.no_grad(): # Correct ':'\n",
    "                generated_sample = diffusion_sampler.sample(\n",
    "                    model=trained_model,\n",
    "                    condition=condition_tensor, # Pass (B, N_POINTS, XY_DIM)\n",
    "                    shape=(1, SEQ_LEN)\n",
    "                )\n",
    "            generated_tokens = generated_sample.cpu().numpy()[0]; print(f\"\\nGenerated Tokens:\\n{generated_tokens}\")\n",
    "\n",
    "    except Exception as e: # Correct ':'\n",
    "        print(f\"\\nAn error occurred during sampling: {e}\"); import traceback; traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating output for test sample index: 1 ---\n",
      "Ground Truth Tokens (shape (12,)):\n",
      "[ 1  4  5 16 14 12  4 10  2  0  0  0]\n",
      "\n",
      "Condition Tensor shape (on cuda:0): torch.Size([1, 30, 2])\n",
      "\n",
      "Starting generation process...\n",
      "Sampling timestep 1/1000      \n",
      "Sampling complete.\n",
      "\n",
      "Generated Tokens (shape (12,)):\n",
      "[ 1  4  5 16 14 12  5 10  4 10  2  2]\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 1 # Index of the sample to test (e.g., the first one)\n",
    "\n",
    "# --- Basic Checks ---\n",
    "if 'test_data' not in locals() or not test_data:\n",
    "    print(\"ERROR: 'test_data' is not defined or is empty. Cannot perform sampling.\")\n",
    "    # Handle error appropriately, maybe raise exception or skip\n",
    "elif sample_idx >= len(test_data):\n",
    "    print(f\"ERROR: sample_idx ({sample_idx}) is out of bounds for test_data (size {len(test_data)}).\")\n",
    "    # Handle error\n",
    "else:\n",
    "    print(f\"--- Generating output for test sample index: {sample_idx} ---\")\n",
    "\n",
    "    # 1. Prepare the chosen test sample\n",
    "    # We can reuse the Dataset class for convenient processing\n",
    "    try:\n",
    "        test_dataset_for_sampling = SymbolicRegressionDataset(test_data) # Re-create or use existing one if available\n",
    "        test_item = test_dataset_for_sampling[sample_idx]\n",
    "\n",
    "        # Ground Truth Tokens\n",
    "        true_tokens = test_item['token_ids'].numpy()\n",
    "\n",
    "        # Condition Tensor (needs batch dimension and correct device)\n",
    "        condition_sample = test_item['condition'].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        print(f\"Ground Truth Tokens (shape {true_tokens.shape}):\\n{true_tokens}\")\n",
    "        print(f\"\\nCondition Tensor shape (on {condition_sample.device}): {condition_sample.shape}\")\n",
    "\n",
    "        # 2. Instantiate the Diffusion helper (needed for the .sample() method)\n",
    "        # Ensure parameters match those used during training\n",
    "        diffusion_sampler = DiscreteDiffusion(\n",
    "            num_timesteps=NUM_TIMESTEPS,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            device=DEVICE\n",
    "            # schedule_type is implicitly set via BETA_START/END/SCHEDULE_TYPE globals\n",
    "        )\n",
    "\n",
    "        # 3. Ensure the model is on the correct device and in evaluation mode\n",
    "        if 'trained_model' not in locals():\n",
    "             print(\"ERROR: 'trained_model' not found. Please ensure training completed successfully.\")\n",
    "        else:\n",
    "            trained_model.to(DEVICE)\n",
    "            trained_model.eval()\n",
    "\n",
    "            # 4. Generate the sequence using the diffusion sampler\n",
    "            print(\"\\nStarting generation process...\")\n",
    "            with torch.no_grad(): # Disable gradient calculations for inference\n",
    "                generated_sample = diffusion_sampler.sample(\n",
    "                    model=trained_model,\n",
    "                    condition=condition_sample,\n",
    "                    shape=(1, SEQ_LEN) # Generate 1 sequence of length SEQ_LEN\n",
    "                )\n",
    "\n",
    "            # 5. Process and print the generated sequence\n",
    "            generated_tokens = generated_sample.cpu().numpy()[0] # Get the first (only) sequence from batch\n",
    "            print(f\"\\nGenerated Tokens (shape {generated_tokens.shape}):\\n{generated_tokens}\")\n",
    "\n",
    "            # Optional: Add decoding logic if you have a tokenizer mapping IDs to symbols\n",
    "            # try:\n",
    "            #     # Assuming you have a tokenizer instance `my_tokenizer`\n",
    "            #     # with a `decode` method\n",
    "            #     true_equation = my_tokenizer.decode(true_tokens, skip_special_tokens=True)\n",
    "            #     generated_equation = my_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "            #     print(f\"\\nDecoded Ground Truth: {true_equation}\")\n",
    "            #     print(f\"Decoded Generation:   {generated_equation}\")\n",
    "            # except NameError:\n",
    "            #     print(\"\\n(Tokenizer not defined - skipping decoding to symbols)\")\n",
    "            # except Exception as e:\n",
    "            #     print(f\"\\nError during decoding: {e}\")\n",
    "\n",
    "            # Set model back to train mode if you plan to continue training\n",
    "            # trained_model.train()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during sampling: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
